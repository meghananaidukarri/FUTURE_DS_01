# Import Libraries
import tweepy
import pandas as pd
from textblob import TextBlob
import re

# Twitter API credentials (replace with your own keys)
consumer_key = 'YOUR_CONSUMER_KEY'
consumer_secret = 'YOUR_CONSUMER_SECRET'
access_token = 'YOUR_ACCESS_TOKEN'
access_token_secret = 'YOUR_ACCESS_SECRET'

# Authenticate with Twitter API
auth = tweepy.OAuth1UserHandler(consumer_key, consumer_secret, access_token, access_token_secret)
api = tweepy.API(auth)

# Define the keyword or trending topic to search
query = '#TrendingTopic'  # replace with actual trending hashtag or keyword

# Collect tweets
tweets = tweepy.Cursor(api.search_tweets, q=query, lang="en", tweet_mode='extended').items(200)

# Store tweets in list
tweet_list = []

for tweet in tweets:
    tweet_list.append(tweet.full_text)

# Convert to DataFrame
df = pd.DataFrame(tweet_list, columns=['tweet'])

# Text cleaning function
def clean_text(text):
    text = re.sub(r'http\S+', '', text)  # remove URLs
    text = re.sub(r'@\w+', '', text)     # remove mentions
    text = re.sub(r'#', '', text)        # remove hashtag symbol
    text = re.sub(r'\n', ' ', text)      # remove new lines
    text = text.strip()
    return text

# Apply cleaning
df['cleaned_tweet'] = df['tweet'].apply(clean_text)

# Sentiment analysis function
def get_sentiment(text):
    analysis = TextBlob(text)
    if analysis.sentiment.polarity > 0:
        return 'Positive'
    elif analysis.sentiment.polarity == 0:
        return 'Neutral'
    else:
        return 'Negative'

# Apply sentiment
df['sentiment'] = df['cleaned_tweet'].apply(get_sentiment)

# Save cleaned data with sentiments to CSV
df.to_csv('sentiment_data.csv', index=False)

print("Data collection and sentiment analysis complete. Data saved to sentiment_data.csv")

